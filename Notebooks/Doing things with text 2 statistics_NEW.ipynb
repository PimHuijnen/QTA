{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da66f75",
   "metadata": {},
   "source": [
    "# Doing Things with Text 2: Basic textual statistics\n",
    "\n",
    "This notebook introduces basic statistical analysis for a single text document after it has been preprocessed. \n",
    "You will learn to calculate metrics like word counts, lexical diversity, and visualize the most common words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddad389d-8163-4588-a5cb-944e783e1cd5",
   "metadata": {},
   "source": [
    "### Step 0: Install packages (only the first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3127d4e-475c-4e1b-b09f-2fa9e95cd395",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e6a00",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Packages\n",
    "\n",
    "In this notebook, we’ll use the following packages to perform our analysis:\n",
    "- `pathlib.Path`: Provides an object-oriented interface for filesystem paths\n",
    "- `nltk.tokenize`: For splitting text into individual words.\n",
    "- `nltk.corpus.stopwords`: A collection of common words like 'the', 'and', 'is', which are often removed in analysis.\n",
    "- `wordcloud`: Creates a word cloud visualization.\n",
    "- `matplotlib.pyplot`: Allows for creating visualizations like charts and graphs to represent data visually.\n",
    "- `collections.Counter`: A specialized dictionary that counts the occurrences of elements in an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pathlib import Path\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b0731",
   "metadata": {},
   "source": [
    "### Step 2: Define Input and Output Paths\n",
    "\n",
    "Set your input and output directories. This setup allows the notebook to load the text file for analysis and save output images.\n",
    "Make sure to replace 'path/to/your/folder' with the actual folder path containing your text document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output paths\n",
    "indir = Path('/Path/to/indir/')\n",
    "outdir = Path('/Path/to/outdir/')\n",
    "outdir.mkdir(parents=True, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "\n",
    "dataset = 'dataset' # here the name of your actual dataset for output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abf37f-1252-42c8-95c1-32c630bc8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset):\n",
    "    dataset_out = dataset.replace(\" \", \"_\").lower()\n",
    "    return dataset_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e3a653-babf-40e4-b2d2-dbe5da7b91d1",
   "metadata": {},
   "source": [
    "### Step 3: Load Your Text Document\n",
    "\n",
    "Now, load the text document you want to analyze. Make sure the file is in the folder specified in the input path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c950093-f50d-427c-82e0-360c60897583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "file = indir / 'infile.txt'  # replace 'infile.txt' with your actual file name\n",
    "with open(file, encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "print(text[:400])  # Show a sample of the loaded text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea393a90-ad91-4253-8a26-2c0ad9a53664",
   "metadata": {},
   "source": [
    "#### Step 3b: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337fa7ff-74de-4b91-9e6f-429bcb967e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "print(tokens[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d794f8",
   "metadata": {},
   "source": [
    "#### Step 3b (Optional): Define Custom Stop Words\n",
    "\n",
    "You can define additional words to remove from your text. If you leave the list empty, no additional words will be removed.\n",
    "This step is optional but can help refine your analysis if there are specific words you want to exclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb25a3-97b3-44ae-af24-645676494200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_custom_stopwords(tokens, custom_stopwords=None):\n",
    "    \"\"\"Remove custom stopwords from a list of tokens.\"\"\"\n",
    "    if custom_stopwords:\n",
    "        return [word for word in tokens if word.lower() not in custom_stopwords]\n",
    "    return tokens\n",
    "\n",
    "custom_stopwords = [''] # add custom stopwords between '', separated by commas: 'word', 'word', 'word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de44c1-6c67-4a0c-9eb8-8ae02cd8bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply custom stop word removal (or leave text unchanged if list is empty)\n",
    "tokens = remove_custom_stopwords(tokens, custom_stopwords)\n",
    "print(tokens[:20])  # Display sample tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9f174",
   "metadata": {},
   "source": [
    "#### Step 4: Calculate Basic Statistics\n",
    "\n",
    "With our tokenized text, we can now calculate some basic statistics, such as the number of unique words (types)\n",
    "and the total number of words (tokens).\n",
    "\n",
    "word_counts_total below is a counter object that counts the frequency for each of the words in 'tokens'. It feeds the bar chart below. Words that need removed from the bar chart can be put in the custom stopword list custom_words above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83541c0-2087-48c2-adc6-c6ad878198c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words\n",
    "word_counts_total = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5b49c-0555-488f-9db5-44a871b28c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of tokens in %s is: %s\"%(dataset, len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bb9aa0-0de1-48c5-97f5-a61ea0994976",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of types in %s is: %s\" %(dataset, len(word_counts_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641b081e-5c31-4760-9ebb-c00f48b2d49b",
   "metadata": {},
   "source": [
    "**Calculate lexical diversity by dividing number of types by number of tokens (= type token ratio, or TTR)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lexical diversity\n",
    "ttr = len(word_counts_total) / len(tokens)\n",
    "print(f\"The type token ratio of {str(indir)} is: {ttr:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07539374",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Most Common Words in a bar chart\n",
    "\n",
    "We'll plot the most common words in a bar chart and display them in a word cloud.\n",
    "This gives insight into the most frequently occurring words in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73682af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the most common words\n",
    "number_top_words = 20  # Set the number of most common words to display\n",
    "most_common_words = word_counts_total.most_common(number_top_words)\n",
    "\n",
    "# Separate words and counts for plotting\n",
    "words, counts = zip(*most_common_words)\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(words, counts)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Most Common Words\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(outdir / f'{save_dataset(dataset)}_most_common.png', dpi=200, bbox_inches='tight') # change filename as wished\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653358c",
   "metadata": {},
   "source": [
    "### Step 6: Visualize Most Common Words in a Word Cloud\n",
    "\n",
    "A word cloud visualizes word frequency, where the size of each word indicates its frequency. You can customize the background color and colormap of the word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26923e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a word cloud\n",
    "wordcloud = WordCloud(background_color='white', colormap='viridis').generate(text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(outdir / f'{save_dataset(dataset)}_wordcloud.png', dpi=200, bbox_inches='tight') # change filename as wished\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e40739",
   "metadata": {},
   "source": [
    "### Step 7: Visualize Word Frequency by Length\n",
    "\n",
    "Next, we’ll analyze word frequency by word length to understand the distribution of different word lengths in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bff751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words by length\n",
    "word_lengths = {'3 letters': 0, \n",
    "                '4 letters': 0, \n",
    "                '5 letters': 0, \n",
    "                '6 letters': 0, \n",
    "                '7 letters': 0, \n",
    "                '8 letters': 0, \n",
    "                '9 letters': 0, \n",
    "                '10+ letters': 0}\n",
    "\n",
    "for word in tokens:\n",
    "    length = len(word)\n",
    "    if length >= 3 and length <= 9:\n",
    "        word_lengths[f\"{length} letters\"] += 1\n",
    "    elif length >= 10:\n",
    "        word_lengths[\"10+ letters\"] += 1\n",
    "\n",
    "# Plot word frequency by length\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(word_lengths.keys(), word_lengths.values())\n",
    "plt.title(\"Word Frequency by Length\")\n",
    "plt.xlabel(\"Word Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig(outdir / f'{save_dataset(dataset)}_word_length.png', dpi=200, bbox_inches='tight') # change filename as wished\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157c081",
   "metadata": {},
   "source": [
    "### Step 8: Print Most Common Words by Word Length\n",
    "\n",
    "For each word length category, you can examine the most common words. This can highlight patterns in the use of specific word lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length = 13 # Define word length - can be any number\n",
    "top_n = 15 # Number of top-frequency words - can be any number\n",
    "\n",
    "# Define a function to get most common words by length\n",
    "def most_common_words_by_length(tokens, word_length, top_n=top_n):\n",
    "    words = [word for word in tokens if len(word) == word_length]\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(top_n)\n",
    "\n",
    "most_common_n_letter_words = most_common_words_by_length(tokens, word_length)\n",
    "\n",
    "print(\"Most common %s-letter words:\\n\" %(str(word_length)))\n",
    "for word, frequency in most_common_n_letter_words:\n",
    "    print('\\'%s\\': %s' %(word, frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c128bbe6-a1da-4cb9-bcf2-59b0f0bead13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
