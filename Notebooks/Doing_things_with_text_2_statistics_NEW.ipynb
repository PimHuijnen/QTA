{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da66f75",
   "metadata": {},
   "source": [
    "# Doing Things with Text 2: Basic textual statistics\n",
    "\n",
    "This notebook introduces basic statistical analysis for a single text document after it has been preprocessed. \n",
    "You will learn to calculate metrics like word counts, lexical diversity, and visualize the most common words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e6a00",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Packages\n",
    "\n",
    "In this notebook, we’ll use the following packages to perform our analysis:\n",
    "- `nltk.tokenize`: Splits text into individual words.\n",
    "- `wordcloud`: Creates a word cloud visualization.\n",
    "- `matplotlib.pyplot`: Allows us to plot bar charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b0731",
   "metadata": {},
   "source": [
    "### Step 2: Define Input and Output Paths\n",
    "\n",
    "Set your input and output directories. This setup allows the notebook to load the text file for analysis and save output images.\n",
    "Make sure to replace 'path/to/your/folder' with the actual folder path containing your text document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output paths\n",
    "indir = os.path.join('path', 'to', 'your', 'input', 'folder')\n",
    "outdir = os.path.join('path', 'to', 'your', 'output', 'folder')\n",
    "os.makedirs(outdir, exist_ok=True)  # Create output directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e3a653-babf-40e4-b2d2-dbe5da7b91d1",
   "metadata": {},
   "source": [
    "### Step 3: Load Your Text Document\n",
    "\n",
    "Now, load the text document you want to analyze. Make sure the file is in the folder specified in the input path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c950093-f50d-427c-82e0-360c60897583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text file\n",
    "file = os.path.join(indir, 'infile.txt')  # replace 'infile.txt' with your actual file name\n",
    "with open(file, encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "print('Sample text preview:', text[:400])  # Show a sample of the loaded text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d794f8",
   "metadata": {},
   "source": [
    "#### Step 3a (Optional): Define Custom Stop Words\n",
    "\n",
    "You can define additional words to remove from your text. If you leave the list empty, no additional words will be removed.\n",
    "This step is optional but can help refine your analysis if there are specific words you want to exclude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b5979-06d5-443b-a697-43ed3a695dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove custom stop words\n",
    "def remove_custom_stopwords(text, custom_stopwords=[]):\n",
    "    tokens = word_tokenize(text)\n",
    "    if custom_stopwords:\n",
    "        tokens = [word for word in tokens if word.lower() not in custom_stopwords]\n",
    "    return tokens\n",
    "\n",
    "# Set up custom stop words (leave empty if not using additional stop words)\n",
    "custom_stopwords = ['example', 'specific', 'word']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea393a90-ad91-4253-8a26-2c0ad9a53664",
   "metadata": {},
   "source": [
    "#### Step 3b: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3de44c1-6c67-4a0c-9eb8-8ae02cd8bd90",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remove_custom_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply custom stop word removal (or leave text unchanged if list is empty)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m remove_custom_stopwords(text, custom_stopwords)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenized text after optional custom stop word removal:\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokens[:\u001b[38;5;241m20\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_custom_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "# Apply custom stop word removal (or leave text unchanged if list is empty)\n",
    "tokens = remove_custom_stopwords(text, custom_stopwords)\n",
    "print(\"Tokenized text after optional custom stop word removal:\", tokens[:20])  # Display sample tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9f174",
   "metadata": {},
   "source": [
    "### Step 5: Calculate Basic Statistics\n",
    "\n",
    "With our tokenized text, we can now calculate some basic statistics, such as the number of unique words (types)\n",
    "and the total number of words (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total words and unique words\n",
    "word_counts_total = Counter(tokens)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Total words (tokens):\", len(tokens))\n",
    "print(\"Unique words (types):\", len(word_counts_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lexical diversity\n",
    "ttr = len(word_counts_total) / len(tokens)\n",
    "print(f\"Type-Token Ratio (TTR): {ttr:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate lexical diversity\n",
    "ttr = len(word_counts_total) / len(tokens)\n",
    "print(f\"Type-Token Ratio (TTR): {ttr:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07539374",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Most Common Words in a bar chart\n",
    "\n",
    "We'll plot the most common words in a bar chart and display them in a word cloud.\n",
    "This gives insight into the most frequently occurring words in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73682af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the most common words\n",
    "number_top_words = 20  # Set the number of most common words to display\n",
    "most_common_words = word_counts_total.most_common(number_top_words)\n",
    "\n",
    "# Separate words and counts for plotting\n",
    "words, counts = zip(*most_common_words)\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(words, counts)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Most Common Words\")\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653358c",
   "metadata": {},
   "source": [
    "### Step 6: Visualize Most Common Words in a Word Cloud\n",
    "\n",
    "A word cloud visualizes word frequency, where the size of each word indicates its frequency. You can customize the background color and colormap of the word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26923e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and display a word cloud\n",
    "wordcloud = WordCloud(background_color='white', colormap='viridis').generate(text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e40739",
   "metadata": {},
   "source": [
    "### Step 7: Visualize Word Frequency by Length\n",
    "\n",
    "Next, we’ll analyze word frequency by word length to understand the distribution of different word lengths in your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bff751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words by length\n",
    "word_lengths = {'3 letters': 0, \n",
    "                '4 letters': 0, \n",
    "                '5 letters': 0, \n",
    "                '6 letters': 0, \n",
    "                '7 letters': 0, \n",
    "                '8 letters': 0, \n",
    "                '9 letters': 0, \n",
    "                '10+ letters': 0}\n",
    "\n",
    "for word in tokens:\n",
    "    length = len(word)\n",
    "    if length >= 3 and length <= 9:\n",
    "        word_lengths[f\"{length} letters\"] += 1\n",
    "    elif length >= 10:\n",
    "        word_lengths[\"10+ letters\"] += 1\n",
    "\n",
    "# Plot word frequency by length\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(word_lengths.keys(), word_lengths.values())\n",
    "plt.title(\"Word Frequency by Length\")\n",
    "plt.xlabel(\"Word Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6157c081",
   "metadata": {},
   "source": [
    "### Step 8: Print Most Common Words by Word Length\n",
    "\n",
    "For each word length category, you can examine the most common words. This can highlight patterns in the use of specific word lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3854dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to get most common words by length\n",
    "def most_common_words_by_length(tokens, word_length, top_n=10):\n",
    "    words = [word for word in tokens if len(word) == word_length]\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(top_n)\n",
    "\n",
    "# Example: Get the 10 most common 5-letter words\n",
    "most_common_five_letter_words = most_common_words_by_length(tokens, 5)\n",
    "print(\"Most common 5-letter words:\", most_common_five_letter_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
