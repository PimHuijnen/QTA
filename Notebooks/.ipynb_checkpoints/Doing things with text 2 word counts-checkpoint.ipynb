{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing things with text 2\n",
    "\n",
    "## Counting words from a *preprocessed* text\n",
    "\n",
    "This notebook introduces some basic statistics for a single (cleaned) text document\n",
    "\n",
    "**note:** To clean a single text document, use notebook 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this install wordcloud command once if it isn't installed yet\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Packages\n",
    "\n",
    "Here, we're loading a few packages to help with counting and visualizing:\n",
    "- `re`: For regular expressions (patterns used for finding and cleaning text).\n",
    "- `os`: For interacting with the operating system, such as file and directory management.\n",
    "- `wordcloud`: Generates visually appealing word clouds from text data, where word size represents frequency.\n",
    "- `matplotlib.pyplot`: A plotting library used to create static, interactive, and animated visualizations in Python.\n",
    "- `Counter` from `collections`: A specialized dictionary that counts the occurrences of elements in an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set Up Your File Paths\n",
    "\n",
    "Define where your text file is located (input) and where you want to save your processed text (output). You will use os.path.join() to define your paths. This approach is cross-platform, meaning it will work on Windows, macOS, and Linux.\n",
    "\n",
    "Replace 'path', 'to', 'your', 'input', 'folder' with the actual paths to your files. It is not necessary for the output folder to exist. If it doesn't, this code will create it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output paths\n",
    "indir = os.path.join('path', 'to', 'your', 'input', 'folder')  # Example: os.path.join('Users', 'yourname', 'Documents')\n",
    "outdir = os.path.join('path', 'to', 'your', 'output', 'folder')\n",
    "os.makedirs(outdir, exist_ok=True)  # Create the output directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load Your Text Document\n",
    "\n",
    "Now, let's load your text file. Make sure the file is in the folder you specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'infile.txt' # change 'infile' for actual file name\n",
    "file_path = indir + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, encoding='utf8') as f:\n",
    "    text = f.read()\n",
    "print('Sample text preview:', text[:400])  # Show a sample of the loaded text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_name = 'text name' # give your document a single word name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the text as a list called 'input_as_list', splitted into single words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_as_list = [x for x in text.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show a sample of the splitted text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_as_list[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the length of the list (= total number of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(input_as_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Step 4a: Remove custom stop words from 'input_as_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_stop_words(words):\n",
    "    \"\"\" Given a list of words and custom stop words, remove custom stop words \"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in custom_words:\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_words = ['the', 'and', 'that', 'with', 'said', 'this', 'when', \n",
    "                'them', 'were', 'from', 'will', 'there', 'they', 'then', \n",
    "                'their', 'your', 'would', 'only', 'even', 'know', 'could', \n",
    "                'have', 'where', 'come', 'been', 'made', 'well']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_as_list = custom_stop_words(input_as_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Identify and count most common words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Count the total number of types (unique words) in text from 'file' after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_total = Counter(input_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The total number of types in \\'%s\\' is: %s\" %(text_name, len(word_counts_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Calculate lexical diversity by dividing number of types by number of tokens (= type token ratio, or TTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The type token ratio of \\'{text_name}\\' is: {round(len(word_counts_total)/len(input_as_list)*100, 1)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Visualize most common words in a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = word_counts_total.most_common(20) # set the number of most common words to print/plot (here: 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### From https://stackoverflow.com/questions/63018726/counter-and-plot-the-most-common-word-in-a-text ####\n",
    "\n",
    "y = [count for word, count in most_common_total]\n",
    "x = [word for word, count in most_common_total]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.bar(x, y, color='crimson')\n",
    "plt.title(\"Most common terms in %s\" %(text_name))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Terms\")\n",
    "plt.rc('xtick',labelsize=12)\n",
    "plt.rc('ytick',labelsize=12)\n",
    "#plt.yscale('log') # optionally set a log scale for the y-axis\n",
    "plt.xticks(rotation=45)\n",
    "for i, (word, count) in enumerate(most_common_total):\n",
    "    plt.text(i, count, f' {count} ', rotation=45, size=16,\n",
    "             ha='center', va='top' if i < 10 else 'bottom', color='white' if i < 10 else 'black')\n",
    "plt.xlim(-0.6, len(x)-0.4) # optionally set tighter x lims\n",
    "plt.tight_layout() # change the whitespace such that all labels fit nicely\n",
    "plt.savefig(outdir + '%s_most_common.png' %(text_name), dpi=200, bbox_inches='tight') # change filename as wished\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative. Check!\n",
    "\n",
    "# Separate words and counts for plotting\n",
    "words, counts = zip(*most_common_words)\n",
    "\n",
    "# Plot bar chart\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(words, counts)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Most Common Words in %s\" %(text_name))\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualize most common words in a word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Input for the word cloud is the original 'text' variable, because wordcloud works with strings, not lists. We can optionally add a custom word list in the WordCloud command*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cloud = WordCloud(background_color='white', colormap='viridis', stopwords=custom_words).generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(text_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig(outdir + 'wordcloud.png', dpi=200, bbox_inches='tight') # change filename as wished\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Count common words by word length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Visualize distribution of word length in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words by length\n",
    "word_lengths = {'3 letters': 0, \n",
    "                '4 letters': 0, \n",
    "                '5 letters': 0, \n",
    "                '6 letters': 0, \n",
    "                '7 letters': 0, \n",
    "                '8 letters': 0, \n",
    "                '9 letters': 0, \n",
    "                '10+ letters': 0}\n",
    "\n",
    "for word in input_as_list:\n",
    "    length = len(word)\n",
    "    if length >= 3 and length <= 9:\n",
    "        word_lengths[f\"{length} letters\"] += 1\n",
    "    elif length >= 10:\n",
    "        word_lengths[\"10+ letters\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(word_lenghts)), word_lenghts.values(), align='center')\n",
    "plt.title(\"Word Frequency by Length in %s\" %(text_name))\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Word lenghts\")\n",
    "plt.xticks(range(len(word_lengths)), word_lengths.keys(), rotation=45)\n",
    "plt.savefig(outdir + '%s_word_lengths.png' %(text_name), dpi=200, bbox_inches='tight') # change filename as wished\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Print Most Common Words by Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get most common words by length\n",
    "def most_common_words_by_length(tokens, word_length, top_n=15):\n",
    "    words = [word for word in tokens if len(word) == word_length]\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 15 most common n-letter words\n",
    "\n",
    "n = 5\n",
    "\n",
    "most_common_n_letter_words = most_common_words_by_length(input_as_list, n)\n",
    "print(\"Most common %s-letter words in %s:\" %(n, text_name), most_common_n_letter_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
