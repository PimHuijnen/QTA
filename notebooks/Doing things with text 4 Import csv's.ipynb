{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing things with text 4\n",
    "\n",
    "## Importing (and analyzing) multiple texts as one corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize  # needs to be installed first via nltk.download()\n",
    "from nltk.corpus import stopwords  # needs to be installed first via nltk.download()\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define in- and out-directories\n",
    "\n",
    "Indir is a folder on your computer with multiple text files. Outdir is a folder (to be made) to store cleaned versions of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = r'/Users/huijn001/surfdrive/data_lokaal/test/'\n",
    "outdir = r'/Users/huijn001/surfdrive/data_lokaal/test1/'\n",
    "os.makedirs(os.path.dirname(outdir), exist_ok=True) # makes outdir if it doesn't exist already\n",
    "allfiles = glob.glob(os.path.join(indir, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User defined stopwords (for wordcloud and Counter). Change if needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = [] ### add words as list: 'word', 'word', 'word', etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_user_defined_stopword_list(words):\n",
    "    \"\"\" Given a hardcoded list of words and stop words, remove stop words \"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopword_list:\n",
    "            new_words.append(word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import csv's as df (only columns 'date', 'Content' and 'year'), merge into one large dataframe 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for filename in tqdm(allfiles):\n",
    "    df = pd.read_csv(filename, sep=\";\", usecols = ['date', 'Content', 'year'])\n",
    "    df['text_clean'] = df['Content'].str.lower()\n",
    "    df['text_clean'] = [[w for w in word_tokenize(text) if w.isalpha() and len(w) > 3] for text in df['text_clean']] \n",
    "    df['word_count'] = df['text_clean'].str.len()\n",
    "    data = pd.concat([data, df], axis=0, ignore_index=True)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn text_clean content as list into string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_clean_str'] = data['text_clean'].apply(\" \".join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Word clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_list = []\n",
    "\n",
    "for list in data['text_clean']:\n",
    "    all_texts_list.append(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_texts_list[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_string = \" \".join(data['text_clean_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cloud = WordCloud(background_color='white', stopwords=stopword_list).generate(all_texts_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(text_cloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "#plt.savefig('/Users/huijn001/Desktop/got.png', dpi=300, bbox_inches='tight') # To save word cloud to your computer\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date, row in zip(data['date'], data['text_clean']):\n",
    "    row = remove_user_defined_stopword_list(row)\n",
    "    word_counts = Counter(row)\n",
    "    most_common_words = word_counts.most_common(100)\n",
    "    print('Most common words in ' + date)\n",
    "    for word, count in most_common_words:\n",
    "        print('%s: %7d' % (word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize word counts in all texts in a bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### From https://stackoverflow.com/questions/63018726/counter-and-plot-the-most-common-word-in-a-text ####\n",
    "\n",
    "for date, row, total_words in zip(data['date'], data['text_clean'], data['word_count']):\n",
    "    row = remove_user_defined_stopword_list(row)\n",
    "    word_counts = Counter(row)\n",
    "    most_common_words = word_counts.most_common(100)\n",
    "\n",
    "    y = [count for word, count in most_common_words]\n",
    "    x = [word for word, count in most_common_words]\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "    plt.bar(x, y, color='crimson')\n",
    "    plt.title(\"Top term frequencies in \" + str(date))\n",
    "    plt.ylabel(\"Counts\")\n",
    "    #plt.yscale('log') # optionally set a log scale for the y-axis\n",
    "    plt.xticks(rotation=45)\n",
    "    for i, (word, count) in enumerate(most_common_words):\n",
    "        plt.text(i, count, f' {count} ', rotation=45,\n",
    "        ha='center', va='top' if i < 10 else 'bottom', color='white' if i < 10 else 'black')\n",
    "    plt.xlim(-0.6, len(x)-0.4) # optionally set tighter x lims\n",
    "    plt.tight_layout() # change the whitespace such that all labels fit nicely\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
